# Respostas do Trabalho - Pipeline de ML

## IdentificaÃ§Ã£o do Grupo

- **Integrantes:**
  1. Nome: Henrique Pimentel
  2. Nome: Rodrigo M. Barros
  3. Nome: Felipe Gouveia
  4. Nome: Suellyn Schopping

---

## Parte 1: Resultados do Pipeline

### 1.1 O pipeline executou sem erros?
<!-- Marque com X a opÃ§Ã£o correta -->
- [X] Sim
- [ ] NÃ£o

### 1.2 F1-Score obtido:
<!-- Copie o valor exibido ao final da execuÃ§Ã£o -->
```
F1-Score:  0.4043
```

### 1.3 Cole aqui o output final do pipeline:
<!-- Execute: python main.py e copie a saÃ­da -->
```

ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€
INICIANDO PIPELINE DE ML
ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€


[ETAPA 1/4] Carregando dados...
==================================================
EXPLORAÃ‡ÃƒO DOS DADOS
==================================================

**************************************************

SHAPE DO DATAFRAME

Shape: (5000, 8)
==================================================

**************************************************

TIPOS DAS COLUNAS

**************************************************
cliente_id              int64
idade                   int64
renda_mensal          float64
tempo_conta_meses       int64
num_produtos            int64
tem_cartao_credito      int64
score_credito         float64
respondeu_campanha      int64
dtype: object
==================================================

**************************************************

Primeiras 5 linhas

**************************************************
   cliente_id  idade  renda_mensal  tempo_conta_meses  num_produtos  tem_cartao_credito  score_credito  respondeu_campanha
0           1     56      46917.46                229             4                   1          600.0                   1
1           2     69      41274.41                  9             3                   0          758.2                   0
2           3     46      40649.98                 25             2                   1          595.7                   1
3           4     32      44336.79                217             5                   1          584.3                   0
4           5     60      35301.68                225             4                   0          797.8                   0
==================================================
==================================================
FIM DA EXPLORAÃ‡ÃƒO DOS DADOS
==================================================

==================================================

DISTRIBUIÃ‡ÃƒO DO TARGET
------------------------------
**************************************************

CONTAGEM DE CADA VALOR DO TARGET

**************************************************
respondeu_campanha
0    2803
1    2197
Name: count, dtype: int64
==================================================
**************************************************

CONTAGEM DE CADA VALOR DO TARGET

**************************************************
respondeu_campanha
0    0.5606
1    0.4394
Name: proportion, dtype: float64
==================================================

FIM DA DISTRIBUIÃ‡ÃƒO DO TARGET
------------------------------
==================================================

[ETAPA 2/4] Validando dados...
Validando dados...
âœ… Dados vÃ¡lidos!

[ETAPA 3/4] Treinando modelo...
Dados de treino: 4000 registros
Dados de teste: 1000 registros
Treinando modelo...
âœ… Modelo treinado!
Modelo salvo em: models/modelo_campanha.pkl

[ETAPA 4/4] Avaliando modelo...

==================================================
RESULTADOS DA AVALIAÃ‡ÃƒO
==================================================

ğŸ“Š MÃ‰TRICAS:
   Accuracy:  0.5550 (55.50%)
   Precision: 0.4951
   Recall:    0.3416
   F1-Score:  0.4043

ğŸ“‹ MATRIZ DE CONFUSÃƒO:
   Verdadeiros Negativos (TN): 404
   Falsos Positivos (FP):      154
   Falsos Negativos (FN):      291
   Verdadeiros Positivos (TP): 151

==================================================
ğŸ¯ F1-SCORE FINAL: 0.4043
==================================================

âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…
PIPELINE CONCLUÃDO COM SUCESSO!
âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…

ğŸ“ Anote o F1-Score no arquivo RESPOSTAS.md: 0.4043
```

---

## Parte 2: InterpretaÃ§Ã£o dos Resultados

### 2.1 O modelo Ã© bom ou ruim? Por quÃª?
<!-- Considere: F1 de 0.5 seria jogar moeda. Acima de 0.5 = melhor que aleatÃ³rio. -->
  R) O modelo nÃ£o Ã© bom. F1-Score abaixo de 0.5. A quantidade de falsos positivos foi maior que a de positivos verdadeiros, dessa forma demonstrando que terÃ­amos resultado similar ao associar o resultado com algum evento aleatÃ³rio.


### 2.2 O dataset Ã© balanceado ou desbalanceado? Como vocÃª descobriu?
  R) O dataset Ã© relativamente balanceado em relaÃ§Ã£o a classe respondeu_campanha pois temos:
      0    2803   56,06%
      1    2197   43,94%
    O desbalanceamento ocorre quando hÃ¡ uma quantidade  muito maior de uma determinada classe com relaÃ§Ã£o a outra, por exemplo nos casos de detecÃ§Ã£o de fraude nos quais poderÃ­amos ter 99% das amostras em uma classe e apenas 1% em outra.

    **Obs.:** Embora o desbalanceamento nÃ£o seja severo, ampliamos a investigaÃ§Ã£o para entender melhor a baixa performance do modelo. Fizemos anÃ¡lise estatÃ­stica descritiva das variÃ¡veis numÃ©ricas, verificamos a ausÃªncia de valores nulos, avaliamos a presenÃ§a de outliers e ajustamos a divisÃ£o treino-teste com `stratify=y` em `treinar.py`. Esses procedimentos ajudaram a confirmar que a principal limitaÃ§Ã£o estÃ¡ menos em um desbalanceamento extremo da variÃ¡vel alvo e mais na baixa capacidade discriminativa das features disponÃ­veis para separar quem responde e quem nÃ£o responde Ã  campanha.


### 2.3 Por que usamos F1-Score e nÃ£o apenas Accuracy neste caso?
  
  R) A accuracy mede a quantidade de previsÃµes corretas (positivas e negativas) com relaÃ§Ã£o ao total de casos. A accuracy 
     no modelo foi de 55.50%, um pouco acima da probabilidade de escolher um evento aleatÃ³rio.
     No caso atual como os falsos positivos e falsos negativos importam igualmente o F1-Socre Ã© a mÃ©trica mais robusta para avaliar o modelo.

---

## Parte 3: ValidaÃ§Ã£o de Dados

### 3.1 Liste as validaÃ§Ãµes Pandera que vocÃª implementou:
<!-- Descreva cada validaÃ§Ã£o que vocÃª adicionou -->

1. cliente_id: tipo inteiro, nÃ£o permite valores nulos, Ãºnico para cada registro
2. idade: tipo inteiro (18 a 80)
3. renda_mensal: tipo float (1000 a 50000)
4. score_credito: tipo float (300 a 850)
5. respondeu_campanha: tipo inteiro (0 ou 1)

### 3.2 Por que validar dados ANTES de treinar o modelo?
<!-- Pense no contexto de produÃ§Ã£o: o que aconteceria se dados invÃ¡lidos entrassem no modelo? -->

Validar os dados antes de treinar o modelo Ã© fundamental para garantir que o algoritmo esteja aprendendo a partir de informaÃ§Ãµes consistentes e compatÃ­veis com o que esperamos ver em produÃ§Ã£o. Sem essa etapa, valores fora de faixa (ex.: idade negativa, renda absurda), tipos incorretos ou categorias invÃ¡lidas podem entrar silenciosamente no pipeline e afetar o modelo.
---

## Parte 4: Versionamento

### 4.1 Liste os commits que vocÃªs fizeram (copie do git log):
<!-- Execute: git log --oneline e cole aqui -->
```
(cole o output do git log aqui)
```

### 4.2 Por que mensagens de commit descritivas sÃ£o importantes?
<!-- Pense: se outra pessoa olhar o histÃ³rico, vai entender o que foi feito? -->

Mensagens de commit descritivas sÃ£o importantes porque tornam o histÃ³rico do projeto mais assimilÃ¡vel: qualquer pessoa consegue entender rapidamente o que foi alterado e por quÃª em cada passo. Isso facilita localizar uma mudanÃ§a especÃ­fica, revisar decisÃµes e, se necessÃ¡rio, reverter um ponto exato sem ter que abrir e comparar vÃ¡rios arquivos na mÃ£o.


## Parte 5: ReflexÃ£o (Opcional)

### 5.1 Qual foi a maior dificuldade do grupo?

A maior dificuldade do grupo foi lidar com a baixa performance do modelo mesmo apÃ³s a construÃ§Ã£o de um pipeline aparentemente correto. Em um primeiro momento, a expectativa era de que, apÃ³s a validaÃ§Ã£o dos dados com Pandera e o uso de um modelo robusto como o RandomForest, as mÃ©tricas seriam naturalmente altas. No entanto, os resultados iniciais mostraram F1-score em torno de 0,40 e recall baixo para a classe positiva, o que gerou a sensaÃ§Ã£o de que poderia haver algum erro tÃ©cnico no cÃ³digo.

A partir daÃ­, a dificuldade passou a ser interpretar o desempenho do modelo Ã  luz das caracterÃ­sticas dos dados: entender o papel do (des)balanceamento da variÃ¡vel alvo, analisar a matriz de confusÃ£o, olhar para as correlaÃ§Ãµes fracas entre as variÃ¡veis preditoras e o target e aceitar que, mesmo com o pipeline funcionando, o conjunto de atributos fornecido tem poder preditivo limitado. Essa etapa de leitura crÃ­tica dos resultados â€“ ir alÃ©m da â€œaccuracyâ€ e focar em F1, recall e impacto do split treino/teste â€“ foi o ponto mais desafiador para o grupo.


### 5.2 O que vocÃªs fariam diferente se fossem refazer?

Se fÃ´ssemos refazer o trabalho, desde o inÃ­cio jÃ¡ ajustarÃ­amos a etapa de treino para usar divisÃ£o estratificada dos dados, modificando a funÃ§Ã£o dividir_treino_teste em treinar.py para incluir stratify=y no train_test_split. Esse ajuste simples deixou a avaliaÃ§Ã£o mais justa (mantendo a proporÃ§Ã£o de classes em treino e teste) e resultou em uma melhora discreta, porÃ©m relevante, com o F1-score passando de aproximadamente 0,40 para 0,46 e aumento do recall da classe positiva. AlÃ©m disso, olharÃ­amos desde o comeÃ§o com mais cuidado para mÃ©tricas como F1 e recall, em vez de depender principalmente da accuracy, que neste problema fica muito prÃ³xima de um baseline simples e esconde parte das dificuldades reais do modelo em identificar quem responde Ã  campanha.

---

**Data de entrega:** ___/___/______
